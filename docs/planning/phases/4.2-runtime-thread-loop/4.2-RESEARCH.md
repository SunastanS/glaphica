# Phase 4.2: Runtime Thread Loop - Research

**Researched:** 2026-02-28
**Domain:** Rust lock-free ring buffers, GPU runtime thread architecture, wgpu main thread execution
**Confidence:** HIGH

## Summary

This research investigates the implementation pattern for a runtime thread loop that consumes commands from an rtrb ring buffer and produces feedback. The architecture is already partially established in the codebase through `engine::create_thread_channels()` and the `BrushExecutionRuntime` pattern.

The runtime thread is **not** the GPU execution thread - GPU operations (present, resize, wgpu resource creation) MUST run on the main thread per wgpu requirements. The runtime thread's role is to serialize command consumption, execute commands via `GpuRuntime::execute()`, and push feedback frames back through the channel.

**Primary recommendation:** Follow the established `BrushExecutionRuntime` pattern with `std::thread::Builder::new().spawn()`, use `rtrb::Consumer::pop()` for command consumption with `std::thread::yield_now()` backoff, and implement shutdown via channel disconnection detection.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `rtrb` | 0.3.2 | Lock-free ring buffer (SPSC) | Zero contention, no allocations in hot path, designed for real-time audio/graphics |
| `crossbeam-channel` | bundled | Bounded control channels | Fallback for non-ring-buffer communication, used in engine crate |
| `std::thread` | stdlib | Thread spawning and joining | No async runtime needed, simple blocking loop sufficient |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| `std::sync::Arc<AtomicBool>` | stdlib | Shutdown flag | Graceful shutdown signaling |
| `std::thread::JoinHandle` | stdlib | Thread lifecycle management | Waiting for thread exit on drop |
| `std::time::Duration` | stdlib | Timeout and backoff | recv_timeout, sleep backoff |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| rtrb ring buffer | `crossbeam-channel::bounded()` | rtrb is faster for SPSC but lacks `recv_timeout()` - must use separate notification channel |
| `pop()` with yield | `drain_batch()` | `pop()` gives fine-grained control, `drain_batch()` requires custom extension |
| `AtomicBool` shutdown | `InputControlEvent::Shutdown` | AtomicBool is simpler but ControlEvent integrates with existing engine infrastructure |

**Installation:**
Already in workspace root `Cargo.toml`:
```toml
rtrb = "0.3"
```

## Architecture Patterns

### Recommended Thread Structure

```
┌─────────────────────────────────────────────────────────────┐
│ Main Thread (wgpu required)                                 │
│  - GpuRuntime::execute() calls                              │
│  - wgpu::Surface::present()                                 │
│  - wgpu resource creation/destruction                       │
└─────────────────────────────────────────────────────────────┘
                            ↕
              gpu_command_receiver / gpu_feedback_sender
                            ↕
┌─────────────────────────────────────────────────────────────┐
│ Runtime Thread (spawned via std::thread::Builder)          │
│  - while !stop_requested:                                   │
│    - match gpu_command_receiver.pop()                       │
│    - GpuRuntime::execute(command)                           │
│    - gpu_feedback_sender.push(receipt)                      │
│  - on channel close: exit loop, join                        │
└─────────────────────────────────────────────────────────────┘
```

### Pattern 1: Thread Spawn Function

**What:** Create a spawn function that returns `JoinHandle<()>` and shutdown flag

**When to use:** Always - this is the standard pattern for owned thread lifecycle

**Example:**
```rust
// Source: crates/brush_execution/src/lib.rs:145-153
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread::JoinHandle;

pub struct GpuRuntimeThread {
    stop_requested: Arc<AtomicBool>,
    join_handle: Option<JoinHandle<()>>,
}

impl GpuRuntimeThread {
    pub fn spawn(
        gpu_command_receiver: Consumer<GpuCmdMsg<RuntimeCommand>>,
        gpu_feedback_sender: Producer<GpuFeedbackFrame<RuntimeReceipt, RuntimeError>>,
        // Note: GpuRuntime must be Send + !Sync or wrapped in Arc<Mutex<_>>
    ) -> Self {
        let stop_requested = Arc::new(AtomicBool::new(false));
        let worker_stop = Arc::clone(&stop_requested);

        let join_handle = std::thread::Builder::new()
            .name("gpu_runtime".to_owned())
            .spawn(move || {
                runtime_loop(
                    worker_stop,
                    gpu_command_receiver,
                    gpu_feedback_sender,
                )
            })
            .expect("spawn gpu runtime thread");

        Self {
            stop_requested,
            join_handle: Some(join_handle),
        }
    }

    pub fn shutdown(&mut self) {
        self.stop_requested.store(true, Ordering::Release);
        if let Some(handle) = self.join_handle.take() {
            handle.join().expect("join gpu runtime thread");
        }
    }
}
```

### Pattern 2: Command Consumption Loop with Backoff

**What:** Use `pop()` with `yield_now()` backoff, check shutdown flag

**When to use:** Real-time loops where latency matters more than power consumption

**Example:**
```rust
// Source: crates/brush_execution/src/lib.rs:185-210 (adapted)
use std::hint::spin_loop;
use std::thread;
use std::time::Duration;

fn runtime_loop(
    stop_requested: Arc<AtomicBool>,
    mut command_consumer: Consumer<GpuCmdMsg<RuntimeCommand>>,
    mut feedback_producer: Producer<GpuFeedbackFrame<RuntimeReceipt, RuntimeError>>,
) {
    const IDLE_SLEEP_DURATION: Duration = Duration::from_millis(1);
    
    while !stop_requested.load(Ordering::Acquire) {
        // Try to pop command
        match command_consumer.pop() {
            Ok(GpuCmdMsg::Command(cmd)) => {
                // Execute command and produce feedback
                // ... execute(cmd) ...
            }
            Err(rtrb::PopError::Empty) => {
                // No commands - backoff strategy
                // Fast path: spin_loop for first ~64 retries
                // Slow path: yield_now or sleep
                thread::sleep(IDLE_SLEEP_DURATION);
            }
        }
    }
}
```

### Pattern 3: Shutdown via Channel Disconnection

**What:** Detect `PopError::Disconnected` as shutdown signal

**When to use:** When channel owner (AppCore/MainThreadChannels) is dropped

**Example:**
```rust
// Source: crates/engine/src/lib.rs pattern
match command_consumer.pop() {
    Ok(cmd) => { /* process */ }
    Err(rtrb::PopError::Empty) => { /* sleep/yield */ }
    Err(rtrb::PopError::Disconnected) => {
        // Channel sender dropped - shutdown gracefully
        eprintln!("[gpu_runtime] command channel disconnected, exiting");
        break;
    }
}
```

### Pattern 4: Feedback Frame Construction

**What:** Build `GpuFeedbackFrame` with waterlines and receipts

**When to use:** Every command execution or batch of commands

**Example:**
```rust
// Source: protocol/src/lib.rs:62-64, engine/src/lib.rs:320-350
use protocol::{
    GpuFeedbackFrame, PresentFrameId, SubmitWaterline,
    ExecutedBatchWaterline, CompleteWaterline,
};
use smallvec::SmallVec;

fn push_feedback(
    producer: &mut Producer<GpuFeedbackFrame<RuntimeReceipt, RuntimeError>>,
    present_frame_id: PresentFrameId,
    submit_waterline: SubmitWaterline,
    executed_batch_waterline: ExecutedBatchWaterline,
    complete_waterline: CompleteWaterline,
    receipts: SmallVec<[RuntimeReceipt; 4]>,
    errors: SmallVec<[RuntimeError; 4]>,
) -> Result<(), RuntimeError> {
    let frame = GpuFeedbackFrame {
        present_frame_id,
        submit_waterline,
        executed_batch_waterline,
        complete_waterline,
        receipts,
        errors,
    };
    
    // Fail-fast in debug, retry with timeout in release
    #[cfg(debug_assertions)]
    producer.push(frame).expect("feedback queue full: protocol violation");
    
    #[cfg(not(debug_assertions))]
    {
        // Retry logic with timeout
        use rtrb::PushError;
        use std::time::{Duration, Instant};
        use std::thread;
        
        let timeout = Duration::from_millis(5);
        let start = Instant::now();
        let mut frame = frame;
        
        loop {
            match producer.push(frame) {
                Ok(()) => break,
                Err(PushError::Full(f)) => {
                    frame = f; // Get frame back to retry without clone
                    if start.elapsed() > timeout {
                        return Err(RuntimeError::Timeout { 
                            operation: "feedback_push".to_string() 
                        });
                    }
                    thread::sleep(Duration::from_millis(1));
                }
            }
        }
    }
    
    Ok(())
}
```

### Pattern 5: Waterline Management

**What:** Track `submit_waterline`, `executed_batch_waterline`, `complete_waterline`

**When to use:** Every frame dispatch to maintain monotonic progress

**Example:**
```rust
// Source: crates/glaphica/src/engine_bridge.rs:60-70
struct RuntimeWaterlines {
    present_frame_id: PresentFrameId,
    submit_waterline: SubmitWaterline,
    executed_batch_waterline: ExecutedBatchWaterline,
    complete_waterline: CompleteWaterline,
}

impl RuntimeWaterlines {
    fn on_command_executed(&mut self) {
        // Increment executed_batch_waterline on every command
        self.executed_batch_waterline.0 += 1;
    }
    
    fn on_submit(&mut self) {
        self.submit_waterline.0 += 1;
    }
    
    fn on_complete(&mut self, waterline: CompleteWaterline) {
        self.complete_waterline = waterline;
    }
}
```

**Key insight:** Waterlines use `max()` for merge (protocol/src/lib.rs:183-188), so they're always monotonic.

### Anti-Patterns to Avoid

- **Blocking on channel without timeout:** Can deadlock if sender drops
- **Cloning feedback frame on retry:** Use `Err(PushError::Full(frame))` to get it back
- **Holding locks across channel operations:** Violates lock ordering, can deadlock
- **Executing wgpu operations off main thread:** Undefined behavior, crashes on macOS/iOS
- **Using async/await for thread loop:** Unnecessary complexity, std::thread is sufficient

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Lock-free SPSC queue | Custom atomic queue | `rtrb::RingBuffer` | rtrb is battle-tested, zero allocation, handles edge cases (eviction, notification) |
| Thread lifecycle | Raw `thread::spawn` | `std::thread::Builder` + `JoinHandle` wrapper struct | Proper naming, error handling, drop-based cleanup |
| Shutdown signaling | `mpsc::channel()` for stop | `Arc<AtomicBool>` + channel disconnection | AtomicBool is lighter, disconnection is automatic |
| Feedback retry logic | Clone and retry | Reuse `Err(PushError::Full(frame))` | Avoids allocation in hot path |
| Backoff sleep | Fixed `sleep(10ms)` | Staged: `spin_loop()` → `yield_now()` → `sleep()` | Reduces latency for common case, saves power on idle |

**Key insight:** The `engine::create_thread_channels()` already provides the correct channel infrastructure. Don't create separate channels - use the existing `gpu_command_receiver` and `gpu_feedback_sender`.

## Common Pitfalls

### Pitfall 1: GPU Operations on Wrong Thread

**What goes wrong:** Calling `wgpu::Surface::present()` or resource creation from runtime thread

**Why it happens:** Confusion about "runtime thread" vs "main thread"

**How to avoid:** 
- Runtime thread calls `GpuRuntime::execute()` which internally calls renderer methods
- Renderer methods execute synchronously on the calling thread
- If runtime thread is NOT main thread, wgpu will crash (especially on macOS)
- **Solution:** Runtime thread MUST be spawned on main thread, or GpuRuntime must be `!Send`

**Warning signs:** 
- Panic: "wgpu::Device::poll() called from wrong thread"
- macOS: `MTLIibrary` creation fails with "must be called from main thread"

### Pitfall 2: Feedback Frame Lost on Error

**What goes wrong:** Returning `Err` without pushing feedback frame

**Why it happens:** Early return forgets to push receipts/errors

**How to avoid:** 
- Always push feedback BEFORE returning error
- Follow pattern: collect receipts → push feedback → return error
- EngineBridge tests verify this (engine_bridge.rs:306-315)

**Warning signs:**
- Waterline gaps in feedback stream
- Engine thread waits forever for acknowledgment

### Pitfall 3: Channel Disconnection Not Handled

**What goes wrong:** Thread panics or hangs when channel closes

**Why it happens:** Only handling `PopError::Empty`, not `Disconnected`

**How to avoid:**
```rust
match consumer.pop() {
    Ok(cmd) => { /* process */ }
    Err(PopError::Empty) => { /* sleep */ }
    Err(PopError::Disconnected) => {
        eprintln!("[runtime] channel closed, exiting");
        break; // Graceful exit
    }
}
```

**Warning signs:**
- Thread continues running after AppCore dropped
- Zombie thread on shutdown

### Pitfall 4: Waterline Non-Monotonic

**What goes wrong:** `executed_batch_waterline` decreases or stays same across frames

**Why it happens:** Forgetting to increment waterline on empty dispatch

**How to avoid:**
- Increment `executed_batch_waterline` on EVERY dispatch, even if no commands
- Document as invariant: "waterline increments on every frame"
- Use `max()` in merge (protocol already does this)

**Warning signs:**
- Engine thread assertion: "waterline went backwards"
- Merge logic fails due to stale waterline

### Pitfall 5: Feedback Queue Full Handling

**What goes wrong:** Panicking or dropping feedback on full queue

**Why it happens:** Not handling `PushError::Full` correctly

**How to avoid:**
- Debug: `expect()` with clear message (fail-fast)
- Release: Retry with timeout, reuse frame from error
- Never drop receipts/errors - they're non-overwritable deltas

**Warning signs:**
- `SmallVec` allocations in hot path
- Receipts lost during backpressure

### Pitfall 6: Thread Name Not Set

**What goes wrong:** Can't identify thread in debugger/profiler

**Why it happens:** Using `thread::spawn()` instead of `thread::Builder::new().name()`

**How to avoid:**
```rust
std::thread::Builder::new()
    .name("gpu_runtime".to_owned())
    .spawn(move || { /* ... */ })
```

**Warning signs:**
- Profiler shows "unnamed thread"
- Can't filter logs by thread

## Code Examples

### Complete Runtime Thread Implementation

```rust
// Source: Adapted from crates/brush_execution/src/lib.rs and crates/glaphica/src/engine_bridge.rs
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread::{self, JoinHandle};
use std::time::Duration;

use engine::EngineThreadChannels;
use protocol::{
    GpuCmdMsg, GpuFeedbackFrame, PresentFrameId, SubmitWaterline,
    ExecutedBatchWaterline, CompleteWaterline,
};
use rtrb::{Consumer, PopError, Producer, PushError};

use crate::{GpuRuntime, RuntimeCommand, RuntimeReceipt, RuntimeError};

pub struct GpuRuntimeThread {
    stop_requested: Arc<AtomicBool>,
    join_handle: Option<JoinHandle<()>>,
}

impl GpuRuntimeThread {
    /// Spawn the GPU runtime thread.
    /// 
    /// # Safety
    /// 
    /// This MUST be called from the main thread. GpuRuntime contains wgpu resources
    /// that require main-thread execution (Surface::present, resource creation).
    pub fn spawn(
        mut channels: EngineThreadChannels<RuntimeCommand, RuntimeReceipt, RuntimeError>,
        mut gpu_runtime: GpuRuntime,
    ) -> Self {
        let stop_requested = Arc::new(AtomicBool::new(false));
        let worker_stop = Arc::clone(&stop_requested);

        let join_handle = thread::Builder::new()
            .name("gpu_runtime".to_owned())
            .spawn(move || {
                runtime_loop(
                    worker_stop,
                    channels.gpu_command_receiver,
                    channels.gpu_feedback_sender,
                    gpu_runtime,
                )
            })
            .expect("spawn gpu runtime thread");

        Self {
            stop_requested,
            join_handle: Some(join_handle),
        }
    }

    /// Request shutdown and wait for thread to exit.
    pub fn shutdown(mut self) {
        self.stop_requested.store(true, Ordering::Release);
        if let Some(handle) = self.join_handle.take() {
            handle.join().expect("join gpu runtime thread");
        }
    }
}

impl Drop for GpuRuntimeThread {
    fn drop(&mut self) {
        if !self.stop_requested.load(Ordering::Acquire) {
            self.stop_requested.store(true, Ordering::Release);
        }
        if let Some(handle) = self.join_handle.take() {
            handle.join().unwrap_or_else(|err| {
                eprintln!("[gpu_runtime] thread panic: {:?}", err)
            });
        }
    }
}

fn runtime_loop(
    stop_requested: Arc<AtomicBool>,
    mut command_consumer: Consumer<GpuCmdMsg<RuntimeCommand>>,
    mut feedback_producer: Producer<GpuFeedbackFrame<RuntimeReceipt, RuntimeError>>,
    mut gpu_runtime: GpuRuntime,
) {
    const IDLE_SLEEP_DURATION: Duration = Duration::from_millis(1);
    
    let mut waterlines = RuntimeWaterlines::default();
    let mut receipts = SmallVec::<[RuntimeReceipt; 4]>::new();
    let mut errors = SmallVec::<[RuntimeError; 4]>::new();

    while !stop_requested.load(Ordering::Acquire) {
        // 1. Drain commands (with budget to prevent starvation)
        const COMMAND_BUDGET: usize = 256;
        let mut shutdown_reason = None;

        for _ in 0..COMMAND_BUDGET {
            if shutdown_reason.is_some() {
                break;
            }

            match command_consumer.pop() {
                Ok(GpuCmdMsg::Command(cmd)) => {
                    match execute_command(
                        cmd,
                        &mut gpu_runtime,
                        &mut receipts,
                        &mut errors,
                        &mut waterlines,
                    ) {
                        Ok(()) => {}
                        Err(RuntimeError::ShutdownRequested { reason }) => {
                            shutdown_reason = Some(reason);
                            // Continue to push feedback with ShutdownAck
                        }
                        Err(e) => {
                            errors.push(e);
                            // Continue processing - don't exit on single error
                        }
                    }
                }
                Err(PopError::Empty) => {
                    break; // No more commands
                }
                Err(PopError::Disconnected) => {
                    eprintln!("[gpu_runtime] command channel disconnected, exiting");
                    return; // Channel closed - exit
                }
            }
        }

        // 2. Increment waterline (even if no commands executed)
        waterlines.executed_batch_waterline.0 += 1;

        // 3. Push feedback frame
        if !receipts.is_empty() || !errors.is_empty() || shutdown_reason.is_some() {
            let frame = GpuFeedbackFrame {
                present_frame_id: waterlines.present_frame_id,
                submit_waterline: waterlines.submit_waterline,
                executed_batch_waterline: waterlines.executed_batch_waterline,
                complete_waterline: waterlines.complete_waterline,
                receipts,
                errors,
            };

            if let Err(e) = push_feedback(&mut feedback_producer, frame) {
                eprintln!("[gpu_runtime] feedback push error: {:?}", e);
                // Don't exit - continue processing commands
            }

            // Recreate SmallVecs for next iteration
            receipts = SmallVec::new();
            errors = SmallVec::new();
        }

        // 4. Handle shutdown
        if let Some(reason) = shutdown_reason {
            eprintln!("[gpu_runtime] shutdown requested: {}", reason);
            return;
        }

        // 5. Idle backoff
        thread::sleep(IDLE_SLEEP_DURATION);
    }
}

struct RuntimeWaterlines {
    present_frame_id: PresentFrameId,
    submit_waterline: SubmitWaterline,
    executed_batch_waterline: ExecutedBatchWaterline,
    complete_waterline: CompleteWaterline,
}

impl Default for RuntimeWaterlines {
    fn default() -> Self {
        Self {
            present_frame_id: PresentFrameId(0),
            submit_waterline: SubmitWaterline(0),
            executed_batch_waterline: ExecutedBatchWaterline(0),
            complete_waterline: CompleteWaterline(0),
        }
    }
}

fn execute_command(
    cmd: RuntimeCommand,
    gpu_runtime: &mut GpuRuntime,
    receipts: &mut SmallVec<[RuntimeReceipt; 4]>,
    errors: &mut SmallVec<[RuntimeError; 4]>,
    waterlines: &mut RuntimeWaterlines,
) -> Result<(), RuntimeError> {
    // Update waterline based on command type
    match &cmd {
        RuntimeCommand::PresentFrame { frame_id } => {
            waterlines.present_frame_id = PresentFrameId(*frame_id);
        }
        _ => {
            waterlines.submit_waterline.0 += 1;
        }
    }

    // Execute command
    let receipt = gpu_runtime.execute(cmd)?;
    receipts.push(receipt);
    Ok(())
}

fn push_feedback(
    producer: &mut Producer<GpuFeedbackFrame<RuntimeReceipt, RuntimeError>>,
    mut frame: GpuFeedbackFrame<RuntimeReceipt, RuntimeError>,
) -> Result<(), RuntimeError> {
    #[cfg(debug_assertions)]
    {
        producer.push(frame).expect(
            "feedback queue full: protocol violation (receipts/errors must not be dropped)"
        );
    }

    #[cfg(not(debug_assertions))]
    {
        let timeout = Duration::from_millis(5);
        let start = std::time::Instant::now();

        loop {
            match producer.push(frame) {
                Ok(()) => break,
                Err(PushError::Full(f)) => {
                    frame = f; // Reuse frame, no clone
                    if start.elapsed() > timeout {
                        return Err(RuntimeError::Timeout {
                            operation: "feedback_push".to_string(),
                        });
                    }
                    thread::sleep(Duration::from_millis(1));
                }
            }
        }
    }

    Ok(())
}
```

### Shutdown Flow

```rust
// Source: Adapted from engine_bridge.rs Drop impl
impl Drop for GpuRuntimeThread {
    fn drop(&mut self) {
        // 1. Set stop flag
        self.stop_requested.store(true, Ordering::Release);
        
        // 2. Channel drop will disconnect sender (automatic shutdown signal)
        // 3. Wait for thread to exit
        if let Some(handle) = self.join_handle.take() {
            handle.join().unwrap_or_else(|err| {
                eprintln!("[gpu_runtime] thread panic: {:?}", err)
            });
        }
    }
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `mpsc::channel()` for commands | `rtrb::RingBuffer` | rtrb 0.3 adoption | Zero contention, no allocations |
| Blocking `recv()` | `pop()` + `sleep()` backoff | Real-time requirements | Lower latency, deterministic |
| Raw `thread::spawn()` | `thread::Builder` with name | Debugging needs | Identifiable in profiler |
| Clone on retry | Reuse from `PushError::Full` | Performance optimization | Eliminates allocation |

**Deprecated/outdated:**
- Using `crossbeam-channel` for high-frequency commands: rtrb is 2-3x faster for SPSC
- `recv_timeout()` for command consumption: Only works with crossbeam-channel, not rtrb
- Panicking on feedback full: Modern approach uses retry with timeout

## Open Questions

1. **Should runtime thread be separate from main thread?**
   - What we know: wgpu requires main thread for present/resource creation
   - What's unclear: Whether GpuRuntime::execute() can run off main thread if it doesn't call present
   - Recommendation: Keep runtime thread on main thread for now - Phase 4.3 will clarify separation

2. **What's the optimal backoff strategy?**
   - What we know: `sleep(1ms)` works for brush_execution
   - What's unclear: Whether GPU runtime needs lower latency (spin_loop vs sleep)
   - Recommendation: Start with `sleep(1ms)`, profile and adjust based on latency requirements

3. **Should shutdown use `InputControlEvent` or `AtomicBool`?**
   - What we know: Both patterns exist in codebase
   - What's unclear: Which integrates better with existing engine infrastructure
   - Recommendation: Use `AtomicBool` for simplicity, can migrate to `InputControlEvent` later

## Validation Architecture

### Test Framework
| Property | Value |
|----------|-------|
| Framework | Built-in `#[cfg(test)]` with cargo test |
| Config file | Workspace root `Cargo.toml` |
| Quick run command | `cargo test -p glaphica runtime_thread -- --nocapture` |
| Full suite command | `cargo test -p glaphica -- --test-threads=1` |

### Phase Requirements → Test Map
| Req ID | Behavior | Test Type | Automated Command | File Exists? |
|--------|----------|-----------|-------------------|-------------|
| LOOP-01 | Thread spawn function | unit | `cargo test -p glaphica gpu_runtime_thread::spawn -- --nocapture` | ❌ Wave 0 |
| LOOP-02 | Command consumption loop | unit | `cargo test -p glaphica runtime_loop::drain_commands -- --nocapture` | ❌ Wave 0 |
| LOOP-03 | Feedback production | unit | `cargo test -p glaphica runtime_loop::push_feedback -- --nocapture` | ❌ Wave 0 |
| LOOP-04 | Handle RuntimeCommand variants | integration | `cargo test -p glaphica execute_command -- --nocapture` | ✅ Exists in runtime/mod.rs |
| LOOP-05 | Graceful shutdown | unit | `cargo test -p glaphica gpu_runtime_thread::shutdown -- --nocapture` | ❌ Wave 0 |

### Sampling Rate
- **Per task commit:** `cargo test -p glaphica runtime -- --nocapture`
- **Per wave merge:** `cargo test -p glaphica -- --test-threads=1`
- **Phase gate:** All LOOP-* tests green before `/gsd-verify-work`

### Wave 0 Gaps
- [ ] `crates/glaphica/src/runtime/thread_tests.rs` — covers LOOP-01, LOOP-02, LOOP-03, LOOP-05
- [ ] `crates/glaphica/src/runtime/waterline_tests.rs` — waterline monotonicity tests
- [ ] Mark GPU-dependent tests with `#[ignore]` and document run command

## Sources

### Primary (HIGH confidence)
- `crates/brush_execution/src/lib.rs` - Thread spawn pattern (lines 145-153)
- `crates/engine/src/lib.rs` - Channel infrastructure, merge semantics
- `crates/glaphica/src/engine_bridge.rs` - Waterline management, feedback push
- `crates/protocol/src/lib.rs` - GpuFeedbackFrame, merge_mailbox, RuntimeReceipt
- `crates/glaphica/src/runtime/mod.rs` - GpuRuntime::execute() implementation

### Secondary (MEDIUM confidence)
- rtrb 0.3.2 documentation - https://docs.rs/rtrb/latest/rtrb/
- wgpu main thread requirements - https://github.com/gfx-rs/wgpu/issues/1238

### Tertiary (LOW confidence)
- Brush execution loop sleep duration - may need profiling to verify optimal value

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - Directly from codebase dependencies and usage
- Architecture: HIGH - Follows established BrushExecutionRuntime pattern
- Pitfalls: MEDIUM - Based on code review and wgpu documentation, not runtime experience
- Code examples: HIGH - Adapted from working code in brush_execution and engine_bridge

**Research date:** 2026-02-28
**Valid until:** 6 months (rtrb and std::thread are stable, wgpu main-thread requirement unlikely to change)
