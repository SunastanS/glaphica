{"_id":"ruvector-onnx-embeddings-wasm","_rev":"3-e99a162bbb73b33ddd8fc2b84c90a908","name":"ruvector-onnx-embeddings-wasm","dist-tags":{"latest":"0.1.2"},"versions":{"0.1.0":{"name":"ruvector-onnx-embeddings-wasm","version":"0.1.0","keywords":["onnx","embeddings","wasm","webassembly","ml","machine-learning","nlp","text-embeddings","semantic-search","vector-database","rag","sentence-transformers","huggingface","cloudflare-workers","edge-computing","browser"],"author":{"name":"RuVector Team"},"license":"MIT","_id":"ruvector-onnx-embeddings-wasm@0.1.0","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector/tree/main/examples/onnx-embeddings-wasm","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"c90fffb1db4731ddb9df2d4f7a3104680b34f4fb","tarball":"https://registry.npmjs.org/ruvector-onnx-embeddings-wasm/-/ruvector-onnx-embeddings-wasm-0.1.0.tgz","fileCount":8,"integrity":"sha512-99DrPM79RVGmDTat4kOhVD1JJFnK3x86kc0lFrFIqztFxMfanNhOwArNKS84Y2Y7FqZt4oE8OR13EtRtpZPInw==","signatures":[{"sig":"MEUCIQCTqdznWfLKBUx6aGfjctU/Q+TmrdC4Su3DXUd9lqjAbwIgBK9Mkwsm5zryAEpmcbQJtH8jrvMeOdxOjL1ZU5lCHV4=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":7653146},"main":"ruvector_onnx_embeddings_wasm.js","type":"module","types":"ruvector_onnx_embeddings_wasm.d.ts","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./ruvector_onnx_embeddings_wasm.d.ts","import":"./ruvector_onnx_embeddings_wasm.js"},"./loader":{"import":"./loader.js"},"./loader.js":{"import":"./loader.js"}},"gitHead":"9d33b4b45d2dcb2449df410b2e0d681e1f87df95","_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git"},"_npmVersion":"9.8.1","description":"Portable WASM embedding generation - run text embeddings in browsers, Cloudflare Workers, Deno, and any WebAssembly runtime","directories":{},"sideEffects":["./ruvector_onnx_embeddings_wasm.js","./snippets/*"],"_nodeVersion":"22.21.1","_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/ruvector-onnx-embeddings-wasm_0.1.0_1767154748199_0.8604339651850976","host":"s3://npm-registry-packages-npm-production"}},"0.1.1":{"name":"ruvector-onnx-embeddings-wasm","version":"0.1.1","keywords":["onnx","embeddings","wasm","webassembly","simd","ml","machine-learning","nlp","text-embeddings","semantic-search","vector-database","rag","sentence-transformers","huggingface","cloudflare-workers","edge-computing","browser"],"author":{"name":"RuVector Team"},"license":"MIT","_id":"ruvector-onnx-embeddings-wasm@0.1.1","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector/tree/main/examples/onnx-embeddings-wasm","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"7a132c1e37fe47b0db620ce65dfcda8c411ca0be","tarball":"https://registry.npmjs.org/ruvector-onnx-embeddings-wasm/-/ruvector-onnx-embeddings-wasm-0.1.1.tgz","fileCount":8,"integrity":"sha512-ahHtlrZcBx3OtStt4qmzEnS4oCSFbOBvxsH6snsX9QZsIm04s4oUV6dA4vqZ27K8ur52qDNfLo4VXLyAnt6Bvg==","signatures":[{"sig":"MEUCIHJvpNbLYEHxN6DmMJfUs8C/9ztEcvDv6mmdcQtp5jZ5AiEAzblkWEd2tq+MeHwLP2evFOx4wNSPwvjGJpwQD8zp4R0=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":7473267},"main":"ruvector_onnx_embeddings_wasm.js","type":"module","types":"ruvector_onnx_embeddings_wasm.d.ts","engines":{"node":">=16.0.0"},"exports":{".":{"types":"./ruvector_onnx_embeddings_wasm.d.ts","import":"./ruvector_onnx_embeddings_wasm.js"},"./loader":{"import":"./loader.js"},"./loader.js":{"import":"./loader.js"}},"gitHead":"1bbd35393486e35c38d270bccfcabf7b804376ee","_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git"},"_npmVersion":"9.8.1","description":"Portable WASM embedding generation with SIMD - run text embeddings in browsers, Cloudflare Workers, Deno, and any WebAssembly runtime","directories":{},"sideEffects":["./ruvector_onnx_embeddings_wasm.js","./snippets/*"],"_nodeVersion":"22.21.1","_hasShrinkwrap":false,"_npmOperationalInternal":{"tmp":"tmp/ruvector-onnx-embeddings-wasm_0.1.1_1767156060480_0.199230675753288","host":"s3://npm-registry-packages-npm-production"}},"0.1.2":{"name":"ruvector-onnx-embeddings-wasm","type":"module","author":{"name":"RuVector Team"},"description":"Portable WASM embedding generation with SIMD and parallel workers - run text embeddings in browsers, Cloudflare Workers, Deno, and Node.js","version":"0.1.2","license":"MIT","repository":{"type":"git","url":"git+https://github.com/ruvnet/ruvector.git"},"homepage":"https://github.com/ruvnet/ruvector/tree/main/examples/onnx-embeddings-wasm","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"main":"ruvector_onnx_embeddings_wasm.js","types":"ruvector_onnx_embeddings_wasm.d.ts","exports":{".":{"types":"./ruvector_onnx_embeddings_wasm.d.ts","import":"./ruvector_onnx_embeddings_wasm.js","require":"./ruvector_onnx_embeddings_wasm.js"},"./loader":{"import":"./loader.js"},"./loader.js":{"import":"./loader.js"},"./parallel":{"import":"./parallel-embedder.mjs"},"./parallel-embedder":{"import":"./parallel-embedder.mjs"}},"sideEffects":false,"keywords":["onnx","embeddings","wasm","webassembly","simd","parallel","worker-threads","ml","machine-learning","nlp","text-embeddings","semantic-search","vector-database","rag","sentence-transformers","huggingface","cloudflare-workers","edge-computing","browser"],"engines":{"node":">=16.0.0"},"_id":"ruvector-onnx-embeddings-wasm@0.1.2","gitHead":"5a5874d403526cf742d71647700a94780ac8fd8b","_nodeVersion":"22.21.1","_npmVersion":"9.8.1","dist":{"integrity":"sha512-U1Xx7BivMkbAns+bXl1J3b2bey4HZzdOwL3CCElxkNXKqP5BMZDYiVnzHmcaYwQ74Qg3iPNpPH5LHR4UOoUMIQ==","shasum":"3de033a137b8c409cbd06b0e26e515ac335be145","tarball":"https://registry.npmjs.org/ruvector-onnx-embeddings-wasm/-/ruvector-onnx-embeddings-wasm-0.1.2.tgz","fileCount":9,"unpackedSize":7479813,"signatures":[{"keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U","sig":"MEYCIQCoWXNRzVDmf0lDW6CiPHN534fObJoZS3VR3sDsicmykAIhAKyeOMS6XZkd2Ar2TnggUPUV+vEMZ0ak6Yu2D+E6hDEC"}]},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"directories":{},"maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages-npm-production","tmp":"tmp/ruvector-onnx-embeddings-wasm_0.1.2_1767157313929_0.7058317228161577"},"_hasShrinkwrap":false}},"time":{"created":"2025-12-31T04:19:08.100Z","modified":"2025-12-31T05:01:54.408Z","0.1.0":"2025-12-31T04:19:08.490Z","0.1.1":"2025-12-31T04:41:00.721Z","0.1.2":"2025-12-31T05:01:54.179Z"},"bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"author":{"name":"RuVector Team"},"license":"MIT","homepage":"https://github.com/ruvnet/ruvector/tree/main/examples/onnx-embeddings-wasm","keywords":["onnx","embeddings","wasm","webassembly","simd","parallel","worker-threads","ml","machine-learning","nlp","text-embeddings","semantic-search","vector-database","rag","sentence-transformers","huggingface","cloudflare-workers","edge-computing","browser"],"repository":{"type":"git","url":"git+https://github.com/ruvnet/ruvector.git"},"description":"Portable WASM embedding generation with SIMD and parallel workers - run text embeddings in browsers, Cloudflare Workers, Deno, and Node.js","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"readme":"# RuVector ONNX Embeddings WASM\n\n[![npm version](https://img.shields.io/npm/v/ruvector-onnx-embeddings-wasm.svg)](https://www.npmjs.com/package/ruvector-onnx-embeddings-wasm)\n[![crates.io](https://img.shields.io/crates/v/ruvector-onnx-embeddings-wasm.svg)](https://crates.io/crates/ruvector-onnx-embeddings-wasm)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![WebAssembly](https://img.shields.io/badge/WebAssembly-654FF0?logo=webassembly&logoColor=white)](https://webassembly.org/)\n\n> **Portable embedding generation that runs anywhere WebAssembly runs**\n\nGenerate text embeddings directly in browsers, Cloudflare Workers, Deno, and any WASM runtime. Built with [Tract](https://github.com/sonos/tract) for pure Rust ONNX inference.\n\n## Features\n\n| Feature | Description |\n|---------|-------------|\n| üåê **Browser Support** | Generate embeddings client-side, no server needed |\n| ‚ö° **Edge Computing** | Deploy to Cloudflare Workers, Vercel Edge, Deno Deploy |\n| üì¶ **Zero Dependencies** | Single WASM binary, no native modules |\n| ü§ó **HuggingFace Models** | Pre-configured URLs for popular models |\n| üîÑ **Auto Caching** | Browser Cache API for instant reloads |\n| üéØ **Same API** | Compatible with native `ruvector-onnx-embeddings` |\n\n## Quick Start\n\n### Browser (ES Modules)\n\n```html\n<script type=\"module\">\nimport init, { WasmEmbedder } from 'https://unpkg.com/ruvector-onnx-embeddings-wasm/ruvector_onnx_embeddings_wasm.js';\nimport { createEmbedder } from 'https://unpkg.com/ruvector-onnx-embeddings-wasm/loader.js';\n\n// Initialize WASM\nawait init();\n\n// Create embedder (downloads model automatically)\nconst embedder = await createEmbedder('all-MiniLM-L6-v2');\n\n// Generate embeddings\nconst embedding = embedder.embedOne(\"Hello, world!\");\nconsole.log(\"Dimension:\", embedding.length); // 384\n\n// Compute similarity\nconst sim = embedder.similarity(\"I love Rust\", \"Rust is great\");\nconsole.log(\"Similarity:\", sim.toFixed(4)); // ~0.85\n</script>\n```\n\n### Node.js\n\n```bash\nnpm install ruvector-onnx-embeddings-wasm\n```\n\n```javascript\nimport { createEmbedder, similarity, embed } from 'ruvector-onnx-embeddings-wasm/loader.js';\n\n// One-liner similarity\nconst score = await similarity(\"I love dogs\", \"I adore puppies\");\nconsole.log(score); // ~0.85\n\n// One-liner embedding\nconst embedding = await embed(\"Hello world\");\nconsole.log(embedding.length); // 384\n\n// Full control\nconst embedder = await createEmbedder('bge-small-en-v1.5');\nconst emb1 = embedder.embedOne(\"First text\");\nconst emb2 = embedder.embedOne(\"Second text\");\n```\n\n### Cloudflare Workers\n\n```javascript\nimport { WasmEmbedder, WasmEmbedderConfig } from 'ruvector-onnx-embeddings-wasm';\n\nexport default {\n  async fetch(request, env) {\n    // Load model from R2 or KV\n    const modelBytes = await env.MODELS.get('model.onnx', 'arrayBuffer');\n    const tokenizerJson = await env.MODELS.get('tokenizer.json', 'text');\n\n    const embedder = new WasmEmbedder(\n      new Uint8Array(modelBytes),\n      tokenizerJson\n    );\n\n    const { text } = await request.json();\n    const embedding = embedder.embedOne(text);\n\n    return Response.json({\n      embedding: Array.from(embedding),\n      dimension: embedding.length\n    });\n  }\n};\n```\n\n## Available Models\n\n| Model | Dimension | Size | Speed | Quality | Best For |\n|-------|-----------|------|-------|---------|----------|\n| **all-MiniLM-L6-v2** ‚≠ê | 384 | 23MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Default, fast |\n| **all-MiniLM-L12-v2** | 384 | 33MB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Better quality |\n| **bge-small-en-v1.5** | 384 | 33MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | State-of-the-art |\n| **bge-base-en-v1.5** | 768 | 110MB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Best quality |\n| **e5-small-v2** | 384 | 33MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Search/retrieval |\n| **gte-small** | 384 | 33MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Multilingual |\n\n## API Reference\n\n### ModelLoader\n\n```javascript\nimport { ModelLoader, MODELS, DEFAULT_MODEL } from './loader.js';\n\n// List available models\nconsole.log(ModelLoader.listModels());\n\n// Load with progress\nconst loader = new ModelLoader({\n  cache: true,\n  onProgress: ({ percent }) => console.log(`${percent}%`)\n});\n\nconst { modelBytes, tokenizerJson, config } = await loader.loadModel('all-MiniLM-L6-v2');\n```\n\n### WasmEmbedder\n\n```typescript\nclass WasmEmbedder {\n  constructor(modelBytes: Uint8Array, tokenizerJson: string);\n\n  static withConfig(\n    modelBytes: Uint8Array,\n    tokenizerJson: string,\n    config: WasmEmbedderConfig\n  ): WasmEmbedder;\n\n  embedOne(text: string): Float32Array;\n  embedBatch(texts: string[]): Float32Array;\n  similarity(text1: string, text2: string): number;\n\n  dimension(): number;\n  maxLength(): number;\n}\n```\n\n### WasmEmbedderConfig\n\n```typescript\nclass WasmEmbedderConfig {\n  constructor();\n  setMaxLength(length: number): WasmEmbedderConfig;\n  setNormalize(normalize: boolean): WasmEmbedderConfig;\n  setPooling(strategy: number): WasmEmbedderConfig;\n  // 0=Mean, 1=Cls, 2=Max, 3=MeanSqrtLen, 4=LastToken\n}\n```\n\n### Utility Functions\n\n```typescript\nfunction cosineSimilarity(a: Float32Array, b: Float32Array): number;\nfunction normalizeL2(embedding: Float32Array): Float32Array;\nfunction version(): string;\nfunction simd_available(): boolean;\n```\n\n## Pooling Strategies\n\n| Value | Strategy | Description |\n|-------|----------|-------------|\n| 0 | **Mean** | Average all tokens (default, recommended) |\n| 1 | **Cls** | Use [CLS] token only (BERT-style) |\n| 2 | **Max** | Max pooling across tokens |\n| 3 | **MeanSqrtLen** | Mean normalized by sqrt(length) |\n| 4 | **LastToken** | Last token (decoder models) |\n\n## Performance\n\n| Environment | Throughput | Latency |\n|-------------|------------|---------|\n| Chrome (M1 Mac) | ~50 texts/sec | ~20ms |\n| Firefox (M1 Mac) | ~45 texts/sec | ~22ms |\n| Node.js 20 | ~80 texts/sec | ~12ms |\n| Cloudflare Workers | ~30 texts/sec | ~33ms |\n| Deno | ~75 texts/sec | ~13ms |\n\n*Tested with all-MiniLM-L6-v2, 128 token inputs*\n\n## Comparison: Native vs WASM\n\n| Aspect | Native (`ort`) | WASM (`tract`) |\n|--------|----------------|----------------|\n| Speed | ‚ö°‚ö°‚ö° Native | ‚ö°‚ö° ~2-3x slower |\n| Browser | ‚ùå | ‚úÖ |\n| Edge Workers | ‚ùå | ‚úÖ |\n| GPU | CUDA, TensorRT | ‚ùå |\n| Bundle Size | ~50MB | ~8MB |\n| Portability | Platform-specific | Universal |\n\n**Use native** for: servers, high throughput, GPU acceleration\n**Use WASM** for: browsers, edge, portability\n\n## Building from Source\n\n```bash\n# Install wasm-pack\ncargo install wasm-pack\n\n# Build for web\nwasm-pack build --target web\n\n# Build for Node.js\nwasm-pack build --target nodejs\n\n# Build for bundlers (webpack, vite)\nwasm-pack build --target bundler\n```\n\n## Use Cases\n\n### Semantic Search\n\n```javascript\nconst embedder = await createEmbedder();\n\n// Index documents\nconst docs = [\"Rust is fast\", \"Python is easy\", \"JavaScript runs everywhere\"];\nconst embeddings = docs.map(d => embedder.embedOne(d));\n\n// Search\nconst query = embedder.embedOne(\"Which language is performant?\");\nconst scores = embeddings.map((e, i) => ({\n  doc: docs[i],\n  score: cosineSimilarity(query, e)\n}));\nscores.sort((a, b) => b.score - a.score);\nconsole.log(scores[0]); // { doc: \"Rust is fast\", score: 0.82 }\n```\n\n### Text Clustering\n\n```javascript\nconst texts = [\n  \"Machine learning is amazing\",\n  \"Deep learning uses neural networks\",\n  \"I love pizza\",\n  \"Italian food is delicious\"\n];\n\nconst embeddings = texts.map(t => embedder.embedOne(t));\n// Use k-means or hierarchical clustering on embeddings\n```\n\n### RAG (Retrieval-Augmented Generation)\n\n```javascript\n// Build knowledge base\nconst knowledge = [\n  \"RuVector is a vector database\",\n  \"Embeddings capture semantic meaning\",\n  // ... more docs\n];\nconst knowledgeEmbeddings = knowledge.map(k => embedder.embedOne(k));\n\n// Retrieve relevant context for LLM\nfunction getContext(query, topK = 3) {\n  const queryEmb = embedder.embedOne(query);\n  const scores = knowledgeEmbeddings.map((e, i) => ({\n    text: knowledge[i],\n    score: cosineSimilarity(queryEmb, e)\n  }));\n  return scores.sort((a, b) => b.score - a.score).slice(0, topK);\n}\n```\n\n## Related Packages\n\n| Package | Runtime | Use Case |\n|---------|---------|----------|\n| [ruvector-onnx-embeddings](https://crates.io/crates/ruvector-onnx-embeddings) | Native | High-performance servers |\n| **ruvector-onnx-embeddings-wasm** | WASM | Browsers, edge, portable |\n\n## License\n\nMIT License - See [LICENSE](../../LICENSE) for details.\n\n---\n\n<p align=\"center\">\n  <b>Part of the RuVector ecosystem</b><br>\n  High-performance vector operations in Rust\n</p>\n","readmeFilename":"README.md"}