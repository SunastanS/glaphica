{"_id":"@ruvector/attention","_rev":"6-808dd83229b334330d519f5f2ba04197","name":"@ruvector/attention","dist-tags":{"latest":"0.1.31"},"versions":{"0.1.0":{"name":"@ruvector/attention","version":"0.1.0","keywords":["attention","transformer","machine-learning","neural-network","napi-rs","rust","multi-head-attention","flash-attention","hyperbolic","mixture-of-experts","graph-attention"],"author":{"name":"rUv","email":"ruv@ruv.io"},"license":"MIT OR Apache-2.0","_id":"@ruvector/attention@0.1.0","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector#readme","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"a9164f7126e20696c639d16ba95d019675144a95","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.0.tgz","fileCount":25,"integrity":"sha512-nVSefWCM/gTZea0oM7Rp4grF8lV/NGpQ4+1+cw/hIwV14BG06+FudY2vOir7ixLRLB1tcgdIWEaEDOJbvzWBGg==","signatures":[{"sig":"MEUCIEXjXTyp9yZRTx3X0mHnrE4CQfY8kXMRE6q5jqI7TswGAiEA8BIKT5hez6enq9MYyNSxiexxTvsJ5g+GPffZrVcKqto=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":99539},"main":"index.js","napi":{"targets":["x86_64-apple-darwin","x86_64-pc-windows-msvc","x86_64-unknown-linux-gnu","x86_64-unknown-linux-musl","aarch64-apple-darwin","aarch64-unknown-linux-gnu","aarch64-unknown-linux-musl","aarch64-pc-windows-msvc"],"binaryName":"attention"},"types":"index.d.ts","engines":{"node":">= 10"},"gitHead":"8a61930d00a6d84b50a039aa479c8041fdf8949a","scripts":{"test":"node --test","build":"napi build --platform --release","version":"napi version","artifacts":"napi artifacts","universal":"napi universal","build:debug":"napi build --platform","prepublishOnly":"napi prepublish -t npm"},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git","directory":"crates/ruvector-attention-node"},"_npmVersion":"9.8.1","description":"High-performance attention mechanisms for Node.js - Transformer, Hyperbolic, Flash, MoE, and Graph attention","directories":{},"_nodeVersion":"22.21.1","publishConfig":{"access":"public","registry":"https://registry.npmjs.org/"},"_hasShrinkwrap":false,"devDependencies":{"@napi-rs/cli":"^2.18.0"},"optionalDependencies":{"@ruvector/attention-darwin-x64":"0.1.0","@ruvector/attention-linux-x64-gnu":"0.1.0","@ruvector/attention-win32-x64-msvc":"0.1.0"},"_npmOperationalInternal":{"tmp":"tmp/attention_0.1.0_1764537007513_0.5366972812570057","host":"s3://npm-registry-packages-npm-production"}},"0.1.1":{"name":"@ruvector/attention","version":"0.1.1","keywords":["attention","transformer","machine-learning","neural-network","napi-rs","rust","multi-head-attention","flash-attention","hyperbolic","mixture-of-experts"],"author":{"name":"rUv","email":"ruv@ruv.io"},"license":"MIT OR Apache-2.0","_id":"@ruvector/attention@0.1.1","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector#readme","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"b0879e518197707d8eae35a63a3970c22539b806","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.1.tgz","fileCount":28,"integrity":"sha512-Bm2w96E4T6oVkUT/dNDdb79BebamuIJIbRnA9mCc23YpLumkb59QqiiQ6Quf7bgot9X2j8QsuGnl4UK601qrdA==","signatures":[{"sig":"MEYCIQCL5U7UKT4V6xGzax4+bdIHiLcf0EYwbqy9vxMvY7SjtQIhAJ7UU+3brcidEvQJ1xpMwuLYURMv+z7Z3cgtLnOaXtN7","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":103761},"main":"index.js","napi":{"targets":["x86_64-pc-windows-msvc","x86_64-apple-darwin","x86_64-unknown-linux-gnu","x86_64-unknown-linux-musl","aarch64-apple-darwin","aarch64-unknown-linux-gnu","aarch64-unknown-linux-musl","aarch64-pc-windows-msvc"],"binaryName":"attention"},"types":"index.d.ts","engines":{"node":">= 10"},"gitHead":"a9c3d4abd994ac275480316b16333a717faa3942","scripts":{"test":"node --test","build":"napi build --platform --release","version":"napi version","artifacts":"napi artifacts","universal":"napi universal","build:debug":"napi build --platform","prepublishOnly":"napi prepublish -t npm"},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git","directory":"crates/ruvector-attention-node"},"_npmVersion":"9.8.1","description":"High-performance attention mechanisms for Node.js","directories":{},"_nodeVersion":"22.21.1","publishConfig":{"access":"public","registry":"https://registry.npmjs.org/"},"_hasShrinkwrap":false,"devDependencies":{"@napi-rs/cli":"^2.18.0"},"optionalDependencies":{"@ruvector/attention-darwin-x64":"0.1.1","@ruvector/attention-linux-x64-gnu":"0.1.1","@ruvector/attention-win32-x64-msvc":"0.1.1"},"_npmOperationalInternal":{"tmp":"tmp/attention_0.1.1_1764541095774_0.8641172491943359","host":"s3://npm-registry-packages-npm-production"}},"0.1.2":{"name":"@ruvector/attention","version":"0.1.2","keywords":["attention","transformer","machine-learning","neural-network","napi-rs","rust","multi-head-attention","flash-attention","hyperbolic","mixture-of-experts"],"author":{"name":"rUv","email":"ruv@ruv.io"},"license":"MIT OR Apache-2.0","_id":"@ruvector/attention@0.1.2","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector#readme","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"db5ea5a9cd1f052bbce6d39ca6738846e5b95c6c","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.2.tgz","fileCount":28,"integrity":"sha512-b6bqr75dfjjzZ0BjUpAMgFLVSg7h8Asfz3K/UeixABaHkvulOgsM9TESRkIP/u7zGqoKQofJBRasN49rOUa9Tw==","signatures":[{"sig":"MEUCIFMvr2EZoqrLOz3MjzMQEPRECfe/3M0l8TubUGLqedzuAiEAjvv8/FtuLPhE9F2Qb/NT59lSoImJWva654PbnuVUhrw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":127338},"main":"index.js","napi":{"targets":["x86_64-pc-windows-msvc","x86_64-apple-darwin","x86_64-unknown-linux-gnu","x86_64-unknown-linux-musl","aarch64-apple-darwin","aarch64-unknown-linux-gnu","aarch64-unknown-linux-musl","aarch64-pc-windows-msvc"],"binaryName":"attention"},"types":"index.d.ts","engines":{"node":">= 10"},"gitHead":"a803d316dff76e194a91c7a2db84253007e057bd","scripts":{"test":"node --test","build":"napi build --platform --release","version":"napi version","artifacts":"napi artifacts","universal":"napi universal","build:debug":"napi build --platform","prepublishOnly":"napi prepublish -t npm"},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git","directory":"crates/ruvector-attention-node"},"_npmVersion":"9.8.1","description":"High-performance attention mechanisms for Node.js","directories":{},"_nodeVersion":"22.21.1","publishConfig":{"access":"public","registry":"https://registry.npmjs.org/"},"_hasShrinkwrap":false,"devDependencies":{"@napi-rs/cli":"^2.18.0"},"optionalDependencies":{"@ruvector/attention-darwin-x64":"0.1.2","@ruvector/attention-linux-x64-gnu":"0.1.2","@ruvector/attention-win32-x64-msvc":"0.1.2"},"_npmOperationalInternal":{"tmp":"tmp/attention_0.1.2_1764779157069_0.003626562299005265","host":"s3://npm-registry-packages-npm-production"}},"0.1.3":{"name":"@ruvector/attention","version":"0.1.3","keywords":["attention","transformer","machine-learning","neural-network","napi-rs","rust","multi-head-attention","flash-attention","hyperbolic","mixture-of-experts"],"author":{"name":"rUv","email":"ruv@ruv.io"},"license":"MIT OR Apache-2.0","_id":"@ruvector/attention@0.1.3","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector#readme","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"9787d065238cd26be33db40bf1d6b37db147b307","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.3.tgz","fileCount":28,"integrity":"sha512-ckyqbQZwMGu3xFajR+rnUaPWiqD1qDtf3xvGi4R5UUEMPwaN90JnZilcBELqIBXY/G7AfQsZOjPCl5Bz5SOOuw==","signatures":[{"sig":"MEUCIQCPugIZlRHV73uy+iub5P3WLd4jC9TNvhYAc+2hjKPk0AIgaO0VHe3XmHgC3Ia/5DhwvGSyBp/2ybN1k6KPGKzHyMw=","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":127338},"main":"index.js","napi":{"targets":["x86_64-pc-windows-msvc","x86_64-apple-darwin","x86_64-unknown-linux-gnu","x86_64-unknown-linux-musl","aarch64-apple-darwin","aarch64-unknown-linux-gnu","aarch64-unknown-linux-musl","aarch64-pc-windows-msvc"],"binaryName":"attention"},"types":"index.d.ts","engines":{"node":">= 10"},"gitHead":"a803d316dff76e194a91c7a2db84253007e057bd","scripts":{"test":"node --test","build":"napi build --platform --release","version":"napi version","artifacts":"napi artifacts","universal":"napi universal","build:debug":"napi build --platform","prepublishOnly":"napi prepublish -t npm"},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git","directory":"crates/ruvector-attention-node"},"_npmVersion":"9.8.1","description":"High-performance attention mechanisms for Node.js","directories":{},"_nodeVersion":"22.21.1","publishConfig":{"access":"public","registry":"https://registry.npmjs.org/"},"_hasShrinkwrap":false,"devDependencies":{"@napi-rs/cli":"^2.18.0"},"optionalDependencies":{"@ruvector/attention-darwin-x64":"0.1.3","@ruvector/attention-linux-x64-gnu":"0.1.3","@ruvector/attention-win32-x64-msvc":"0.1.3"},"_npmOperationalInternal":{"tmp":"tmp/attention_0.1.3_1764780986448_0.3165600001155757","host":"s3://npm-registry-packages-npm-production"}},"0.1.4":{"name":"@ruvector/attention","version":"0.1.4","keywords":["attention","transformer","machine-learning","neural-network","napi-rs","rust","multi-head-attention","flash-attention","hyperbolic","mixture-of-experts"],"author":{"name":"rUv","email":"ruv@ruv.io"},"license":"MIT OR Apache-2.0","_id":"@ruvector/attention@0.1.4","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"homepage":"https://github.com/ruvnet/ruvector#readme","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"dist":{"shasum":"3b18fd90b67bfca29a0243ab106f83132727b010","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.4.tgz","fileCount":28,"integrity":"sha512-IpZuADauKWCzlq72vd1IhlDyr6xppFmJXYncGJ8L3f88pxGGl1A8KO1oXpKdrBmRr4pN5DijwqULn3swl9Hlpg==","signatures":[{"sig":"MEYCIQCuSglK3SKvhZzr8Aw1tKqSH4pNTEXufamFbsoqBXAnXAIhAJ/8U1erFfgSgLqRrnIl6FW4EP9MacbxFOpGrlZedJTu","keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U"}],"unpackedSize":128158},"main":"index.js","napi":{"targets":["x86_64-pc-windows-msvc","x86_64-apple-darwin","x86_64-unknown-linux-gnu","x86_64-unknown-linux-musl","aarch64-apple-darwin","aarch64-unknown-linux-gnu","aarch64-unknown-linux-musl","aarch64-pc-windows-msvc"],"binaryName":"attention"},"types":"index.d.ts","engines":{"node":">= 10"},"gitHead":"b5b4858a26debd612e5ddbc80964d048dba401ff","scripts":{"test":"node --test","build":"napi build --platform --release","version":"napi version","artifacts":"napi artifacts","universal":"napi universal","build:debug":"napi build --platform","prepublishOnly":"napi prepublish -t npm"},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"repository":{"url":"git+https://github.com/ruvnet/ruvector.git","type":"git","directory":"crates/ruvector-attention-node"},"_npmVersion":"9.8.1","description":"High-performance attention mechanisms for Node.js","directories":{},"_nodeVersion":"22.21.1","publishConfig":{"access":"public","registry":"https://registry.npmjs.org/"},"_hasShrinkwrap":false,"devDependencies":{"@napi-rs/cli":"^2.18.0"},"optionalDependencies":{"@ruvector/attention-darwin-x64":"0.1.4","@ruvector/attention-linux-x64-gnu":"0.1.4","@ruvector/attention-win32-x64-msvc":"0.1.4"},"_npmOperationalInternal":{"tmp":"tmp/attention_0.1.4_1767557631820_0.2928830036230463","host":"s3://npm-registry-packages-npm-production"}},"0.1.31":{"name":"@ruvector/attention","version":"0.1.31","description":"High-performance attention mechanisms with 7 mathematical theories: Optimal Transport, Mixed Curvature, Topology, Information Geometry, Information Bottleneck, PDE/Diffusion, Unified Diagnostics","main":"index.js","types":"index.d.ts","license":"MIT","repository":{"type":"git","url":"git+https://github.com/ruvnet/ruvector.git"},"keywords":["attention","transformer","machine-learning","optimal-transport","hyperbolic","topology"],"optionalDependencies":{"@ruvector/attention-linux-x64-gnu":"0.1.31","@ruvector/attention-linux-arm64-gnu":"0.1.31","@ruvector/attention-darwin-x64":"0.1.31","@ruvector/attention-darwin-arm64":"0.1.31","@ruvector/attention-win32-x64-msvc":"0.1.31"},"_id":"@ruvector/attention@0.1.31","gitHead":"d772890b1f0e1bf7c5d32e44255e0f522bd0b129","bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"homepage":"https://github.com/ruvnet/ruvector#readme","_nodeVersion":"20.20.0","_npmVersion":"10.8.2","dist":{"integrity":"sha512-xZC1EKuR8dop64LGy0wDyiMmMnxZtTalvIy3hZSCQglM8jxV+zlj1xPDiAQVl/aZZJ59K1UaGq3J1U552EOSxA==","shasum":"a80b971d9d001f107126f8a1deead23f5ae902f9","tarball":"https://registry.npmjs.org/@ruvector/attention/-/attention-0.1.31.tgz","fileCount":3,"unpackedSize":1980,"signatures":[{"keyid":"SHA256:DhQ8wR5APBvFHLF/+Tc+AYvPOdTpcIDqOhxsBHRwC7U","sig":"MEQCIDZ48eHJLeCOaPJW1MOMiIrgyhUL4KwWMpOjZKB2mryVAiBNl5qToe5ElFAf07AHNvQfJ0RHX44u2pR8ZRsP9Ye/6g=="}]},"_npmUser":{"name":"ruvnet","email":"ruv@ruv.net"},"directories":{},"maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"_npmOperationalInternal":{"host":"s3://npm-registry-packages-npm-production","tmp":"tmp/attention_0.1.31_1771701206284_0.47082635459267963"},"_hasShrinkwrap":false}},"time":{"created":"2025-11-30T21:10:07.455Z","modified":"2026-02-21T19:13:26.575Z","0.1.0":"2025-11-30T21:10:07.716Z","0.1.1":"2025-11-30T22:18:15.962Z","0.1.2":"2025-12-03T16:25:57.259Z","0.1.3":"2025-12-03T16:56:26.669Z","0.1.4":"2026-01-04T20:13:51.982Z","0.1.31":"2026-02-21T19:13:26.424Z"},"bugs":{"url":"https://github.com/ruvnet/ruvector/issues"},"license":"MIT","homepage":"https://github.com/ruvnet/ruvector#readme","keywords":["attention","transformer","machine-learning","optimal-transport","hyperbolic","topology"],"repository":{"type":"git","url":"git+https://github.com/ruvnet/ruvector.git"},"description":"High-performance attention mechanisms with 7 mathematical theories: Optimal Transport, Mixed Curvature, Topology, Information Geometry, Information Bottleneck, PDE/Diffusion, Unified Diagnostics","maintainers":[{"name":"ruvnet","email":"ruv@ruv.net"}],"readme":"ERROR: No README data found!","readmeFilename":""}